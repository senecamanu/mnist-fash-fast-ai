{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "!activate tf_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10FolderPath = 'cifar-10-batches-py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLProg(tqdm):\n",
    "    nthblock = 0\n",
    "    \n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.nthblock) * block_size)\n",
    "        self.nthblock = block_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try not running this again lmao\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProg(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve('https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "                   'cifar-10-python.tar.gz',\n",
    "                   pbar.hook)\n",
    "        \n",
    "if not isdir(cifar10FolderPath):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lblnames = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog',\n",
    "    'horse', 'ship', 'truck'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar10_load_batch(cifar10FolderPath, batch_id):\n",
    "    with open(cifar10FolderPath + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is latin1\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    lbls = batch['labels']\n",
    "    \n",
    "    return features, lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaystats(cifar10FolderPath, batch_id, sample_id):\n",
    "    features, lbls = cifar10_load_batch(cifar10FolderPath, batch_id)\n",
    "    \n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}. {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "    \n",
    "    print('\\nStats of batch #{}'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "    \n",
    "#     lblnames = lblnames\n",
    "    lblcounts = dict(zip(*np.unique(lbls, return_counts=True)))\n",
    "    \n",
    "    for key, value in lblcounts.items():\n",
    "        print('Label Counts of [{}][{}]: {}'.format(key, lblnames[key].upper(), value))\n",
    "        \n",
    "    sampleimg = features[sample_id]\n",
    "    samplelbl = lbls[sample_id]\n",
    "    \n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Vallue: {} Max Value: {}'.format(sampleimg.min(), sampleimg.max()))\n",
    "    print('Image - Shape: {}'.format(sampleimg.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(samplelbl, lblnames[samplelbl]))\n",
    "    \n",
    "    plt.imshow(sampleimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch #3\n",
      "# of Samples: 10000\n",
      "\n",
      "Label Counts of [0][AIRPLANE]: 994\n",
      "Label Counts of [1][AUTOMOBILE]: 1042\n",
      "Label Counts of [2][BIRD]: 965\n",
      "Label Counts of [3][CAT]: 997\n",
      "Label Counts of [4][DEER]: 990\n",
      "Label Counts of [5][DOG]: 1029\n",
      "Label Counts of [6][FROG]: 978\n",
      "Label Counts of [7][HORSE]: 1015\n",
      "Label Counts of [8][SHIP]: 961\n",
      "Label Counts of [9][TRUCK]: 1029\n",
      "\n",
      "Example of Image 7000:\n",
      "Image - Min Vallue: 24 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batchid = 3\n",
    "sampleid = 7000\n",
    "displaystats(cifar10FolderPath, batchid, sampleid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    minv = np.min(x)\n",
    "    maxv = np.max(x)\n",
    "    return (x - minv) / (maxv - minv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    enc = np.zeros((len(x), 10))\n",
    "    for index, value in enumerate(x):\n",
    "        enc[index][value] = 1\n",
    "        \n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_save(normalize, one_hot_encode, features, lbls, filename):\n",
    "    features = normalize(features)\n",
    "    lbls = one_hot_encode(lbls)\n",
    "    \n",
    "    pickle.dump((features, lbls), open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_save_data(cifar10FolderPath, normalize, one_hot_encode):\n",
    "    nbatch = 5\n",
    "    validfeatures = []\n",
    "    validlbls = []\n",
    "    \n",
    "    for batchindex in range(1, nbatch + 1):\n",
    "        features, lbls = cifar10_load_batch(cifar10FolderPath, batchindex)\n",
    "        validationindex = int(len(features) * .1)\n",
    "        preproc_save(normalize, one_hot_encode,\n",
    "                    features[:-validationindex],\n",
    "                    lbls[:-validationindex],\n",
    "                    'preprocess_batch_' + str(batchindex) + '.p')\n",
    "        \n",
    "        validfeatures.extend(features[-validationindex:])\n",
    "        validlbls.extend(lbls[-validationindex:])\n",
    "        \n",
    "    preproc_save(normalize, one_hot_encode,\n",
    "                np.array(validfeatures),\n",
    "                np.array(validlbls),\n",
    "                'preprocess_validation.p')\n",
    "    \n",
    "    with open(cifar10FolderPath + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    testfeatures = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    testlbls = batch['labels']\n",
    "    \n",
    "    preproc_save(normalize, one_hot_encode, np.array(testfeatures), np.array(testlbls),\n",
    "                'preprocess.training.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "preproc_save_data(cifar10FolderPath, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "validfeatures, validlbls = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='output_x')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10), name='output_y')\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_net(x, keep_prob):\n",
    "    c1filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=.08))\n",
    "    c2filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=.08))    \n",
    "    c3filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 128, 256], mean=0, stddev=.08))    \n",
    "    c4filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 256, 512], mean=0, stddev=.08))\n",
    "    \n",
    "    # 1, 2\n",
    "    c1 = tf.nn.conv2d(x, c1filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    c1 = tf.nn.relu(c1)\n",
    "    c1pool = tf.nn.max_pool(c1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    c1bn = tf.layers.batch_normalization(c1pool)\n",
    "    \n",
    "    # 3, 4\n",
    "    c2 = tf.nn.conv2d(c1bn, c2filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    c2 = tf.nn.relu(c2)\n",
    "    c2pool = tf.nn.max_pool(c2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    c2bn = tf.layers.batch_normalization(c2pool)\n",
    "    \n",
    "    # 5, 6\n",
    "    c3 = tf.nn.conv2d(c2bn, c3filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    c3 = tf.nn.relu(c3)\n",
    "    c3pool = tf.nn.max_pool(c3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    c3bn = tf.layers.batch_normalization(c3pool)\n",
    "    \n",
    "    # 7, 8\n",
    "    c4 = tf.nn.conv2d(c3bn, c4filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    c4 = tf.nn.relu(c4)\n",
    "    c4pool = tf.nn.max_pool(c4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    c4bn = tf.layers.batch_normalization(c4pool)\n",
    "    \n",
    "    # 9\n",
    "    flat = tf.contrib.layers.flatten(c4bn)\n",
    "    \n",
    "    # 10\n",
    "    full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=128, activation_fn=tf.nn.relu)\n",
    "    full1 = tf.nn.dropout(full1, keep_prob)\n",
    "    full1 = tf.layers.batch_normalization(full1)\n",
    "    \n",
    "    # 11\n",
    "    full2 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=256, activation_fn=tf.nn.relu)\n",
    "    full2 = tf.nn.dropout(full2, keep_prob)\n",
    "    full2 = tf.layers.batch_normalization(full2)\n",
    "    \n",
    "    # 11\n",
    "    full3 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "    full3 = tf.nn.dropout(full3, keep_prob)\n",
    "    full3 = tf.layers.batch_normalization(full3)\n",
    "    \n",
    "    # 12\n",
    "    full4 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=1024, activation_fn=tf.nn.relu)\n",
    "    full4 = tf.nn.dropout(full4, keep_prob)\n",
    "    full4 = tf.layers.batch_normalization(full4)\n",
    "    \n",
    "    # 13\n",
    "    out = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=10, activation_fn=None)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 60\n",
    "keep_probability = .7\n",
    "learning_rate = .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = convolution_net(x, keep_prob)\n",
    "model = tf.identity(logits, name='logits')\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    session.run(optimizer,\n",
    "               feed_dict={\n",
    "                   x: feature_batch,\n",
    "                   y: label_batch,\n",
    "                   keep_prob: keep_probability\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    loss = sess.run(cost,\n",
    "                   feed_dict = {\n",
    "                       x: feature_batch,\n",
    "                       y: label_batch,\n",
    "                       keep_prob: 1.\n",
    "                   })\n",
    "    \n",
    "    valid_acc = sess.run(accuracy,\n",
    "                        feed_dict = {\n",
    "                            x: validfeatures,\n",
    "                            y: validlbls,\n",
    "                            keep_prob: 1.\n",
    "                        }) \n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {}:.6f'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features_lbl(features, lbls, batch_size):\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], lbls[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preproc_train_batch(batch_id, batch_size):\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, lbls = pickle.load(open(filename, mode='rb'))\n",
    "    \n",
    "    return batch_features_lbl(features, lbls, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training!...\n",
      "Epoch  1, CIFAR-10 Batch 1:Loss:     1.8113 Validation Accuracy: 0.4023999869823456:.6f\n",
      "Epoch  1, CIFAR-10 Batch 2:Loss:     1.3252 Validation Accuracy: 0.5062000155448914:.6f\n",
      "Epoch  1, CIFAR-10 Batch 3:Loss:     1.0419 Validation Accuracy: 0.5645999908447266:.6f\n",
      "Epoch  1, CIFAR-10 Batch 4:Loss:     0.9885 Validation Accuracy: 0.6096000075340271:.6f\n",
      "Epoch  1, CIFAR-10 Batch 5:Loss:     0.8661 Validation Accuracy: 0.6348000168800354:.6f\n",
      "Epoch  2, CIFAR-10 Batch 1:Loss:     1.2291 Validation Accuracy: 0.6349999904632568:.6f\n",
      "Epoch  2, CIFAR-10 Batch 2:Loss:     0.8315 Validation Accuracy: 0.6615999937057495:.6f\n",
      "Epoch  2, CIFAR-10 Batch 3:Loss:     0.5433 Validation Accuracy: 0.6638000011444092:.6f\n",
      "Epoch  2, CIFAR-10 Batch 4:Loss:     0.6388 Validation Accuracy: 0.6934000253677368:.6f\n",
      "Epoch  2, CIFAR-10 Batch 5:Loss:     0.5135 Validation Accuracy: 0.7084000110626221:.6f\n",
      "Epoch  3, CIFAR-10 Batch 1:Loss:     0.8689 Validation Accuracy: 0.7013999819755554:.6f\n",
      "Epoch  3, CIFAR-10 Batch 2:Loss:     0.5863 Validation Accuracy: 0.6840000152587891:.6f\n",
      "Epoch  3, CIFAR-10 Batch 3:Loss:     0.2494 Validation Accuracy: 0.6966000199317932:.6f\n",
      "Epoch  3, CIFAR-10 Batch 4:Loss:     0.3824 Validation Accuracy: 0.7156000137329102:.6f\n",
      "Epoch  3, CIFAR-10 Batch 5:Loss:     0.2988 Validation Accuracy: 0.724399983882904:.6f\n",
      "Epoch  4, CIFAR-10 Batch 1:Loss:     0.4997 Validation Accuracy: 0.7188000082969666:.6f\n",
      "Epoch  4, CIFAR-10 Batch 2:Loss:     0.2769 Validation Accuracy: 0.7182000279426575:.6f\n",
      "Epoch  4, CIFAR-10 Batch 3:Loss:     0.1586 Validation Accuracy: 0.7253999710083008:.6f\n",
      "Epoch  4, CIFAR-10 Batch 4:Loss:     0.2685 Validation Accuracy: 0.7192000150680542:.6f\n",
      "Epoch  4, CIFAR-10 Batch 5:Loss:     0.1466 Validation Accuracy: 0.7373999953269958:.6f\n",
      "Epoch  5, CIFAR-10 Batch 1:Loss:     0.3345 Validation Accuracy: 0.7210000157356262:.6f\n",
      "Epoch  5, CIFAR-10 Batch 2:Loss:     0.1560 Validation Accuracy: 0.7328000068664551:.6f\n",
      "Epoch  5, CIFAR-10 Batch 3:Loss:     0.0575 Validation Accuracy: 0.7211999893188477:.6f\n",
      "Epoch  5, CIFAR-10 Batch 4:Loss:     0.1359 Validation Accuracy: 0.7080000042915344:.6f\n",
      "Epoch  5, CIFAR-10 Batch 5:Loss:     0.0437 Validation Accuracy: 0.7253999710083008:.6f\n",
      "Epoch  6, CIFAR-10 Batch 1:Loss:     0.1552 Validation Accuracy: 0.70660001039505:.6f\n",
      "Epoch  6, CIFAR-10 Batch 2:Loss:     0.1002 Validation Accuracy: 0.7447999715805054:.6f\n",
      "Epoch  6, CIFAR-10 Batch 3:Loss:     0.0435 Validation Accuracy: 0.7110000252723694:.6f\n",
      "Epoch  6, CIFAR-10 Batch 4:Loss:     0.0702 Validation Accuracy: 0.724399983882904:.6f\n",
      "Epoch  6, CIFAR-10 Batch 5:Loss:     0.0701 Validation Accuracy: 0.7325999736785889:.6f\n",
      "Epoch  7, CIFAR-10 Batch 1:Loss:     0.0595 Validation Accuracy: 0.7185999751091003:.6f\n",
      "Epoch  7, CIFAR-10 Batch 2:Loss:     0.0507 Validation Accuracy: 0.7275999784469604:.6f\n",
      "Epoch  7, CIFAR-10 Batch 3:Loss:     0.0366 Validation Accuracy: 0.7179999947547913:.6f\n",
      "Epoch  7, CIFAR-10 Batch 4:Loss:     0.0351 Validation Accuracy: 0.7211999893188477:.6f\n",
      "Epoch  7, CIFAR-10 Batch 5:Loss:     0.0126 Validation Accuracy: 0.7318000197410583:.6f\n",
      "Epoch  8, CIFAR-10 Batch 1:Loss:     0.0473 Validation Accuracy: 0.7275999784469604:.6f\n",
      "Epoch  8, CIFAR-10 Batch 2:Loss:     0.0254 Validation Accuracy: 0.7247999906539917:.6f\n",
      "Epoch  8, CIFAR-10 Batch 3:Loss:     0.0064 Validation Accuracy: 0.7346000075340271:.6f\n",
      "Epoch  8, CIFAR-10 Batch 4:Loss:     0.0184 Validation Accuracy: 0.7287999987602234:.6f\n",
      "Epoch  8, CIFAR-10 Batch 5:Loss:     0.0136 Validation Accuracy: 0.7365999817848206:.6f\n",
      "Epoch  9, CIFAR-10 Batch 1:Loss:     0.0260 Validation Accuracy: 0.727400004863739:.6f\n",
      "Epoch  9, CIFAR-10 Batch 2:Loss:     0.0078 Validation Accuracy: 0.7296000123023987:.6f\n",
      "Epoch  9, CIFAR-10 Batch 3:Loss:     0.0160 Validation Accuracy: 0.7121999859809875:.6f\n",
      "Epoch  9, CIFAR-10 Batch 4:Loss:     0.0233 Validation Accuracy: 0.7089999914169312:.6f\n",
      "Epoch  9, CIFAR-10 Batch 5:Loss:     0.0132 Validation Accuracy: 0.7268000245094299:.6f\n",
      "Epoch 10, CIFAR-10 Batch 1:Loss:     0.0439 Validation Accuracy: 0.7131999731063843:.6f\n",
      "Epoch 10, CIFAR-10 Batch 2:Loss:     0.0160 Validation Accuracy: 0.7275999784469604:.6f\n",
      "Epoch 10, CIFAR-10 Batch 3:Loss:     0.0125 Validation Accuracy: 0.739799976348877:.6f\n",
      "Epoch 10, CIFAR-10 Batch 4:Loss:     0.0103 Validation Accuracy: 0.7300000190734863:.6f\n",
      "Epoch 10, CIFAR-10 Batch 5:Loss:     0.0090 Validation Accuracy: 0.7311999797821045:.6f\n",
      "Epoch 11, CIFAR-10 Batch 1:Loss:     0.0332 Validation Accuracy: 0.7329999804496765:.6f\n",
      "Epoch 11, CIFAR-10 Batch 2:Loss:     0.0129 Validation Accuracy: 0.7297999858856201:.6f\n",
      "Epoch 11, CIFAR-10 Batch 3:Loss:     0.0139 Validation Accuracy: 0.7264000177383423:.6f\n",
      "Epoch 11, CIFAR-10 Batch 4:Loss:     0.0489 Validation Accuracy: 0.7382000088691711:.6f\n",
      "Epoch 11, CIFAR-10 Batch 5:Loss:     0.0066 Validation Accuracy: 0.7351999878883362:.6f\n",
      "Epoch 12, CIFAR-10 Batch 1:Loss:     0.0185 Validation Accuracy: 0.7441999912261963:.6f\n",
      "Epoch 12, CIFAR-10 Batch 2:Loss:     0.0142 Validation Accuracy: 0.7296000123023987:.6f\n",
      "Epoch 12, CIFAR-10 Batch 3:Loss:     0.0161 Validation Accuracy: 0.7111999988555908:.6f\n",
      "Epoch 12, CIFAR-10 Batch 4:Loss:     0.0213 Validation Accuracy: 0.729200005531311:.6f\n",
      "Epoch 12, CIFAR-10 Batch 5:Loss:     0.0050 Validation Accuracy: 0.7319999933242798:.6f\n",
      "Epoch 13, CIFAR-10 Batch 1:Loss:     0.0096 Validation Accuracy: 0.7135999798774719:.6f\n",
      "Epoch 13, CIFAR-10 Batch 2:Loss:     0.0140 Validation Accuracy: 0.7336000204086304:.6f\n",
      "Epoch 13, CIFAR-10 Batch 3:Loss:     0.0056 Validation Accuracy: 0.7426000237464905:.6f\n",
      "Epoch 13, CIFAR-10 Batch 4:Loss:     0.0086 Validation Accuracy: 0.7369999885559082:.6f\n",
      "Epoch 13, CIFAR-10 Batch 5:Loss:     0.0042 Validation Accuracy: 0.7297999858856201:.6f\n",
      "Epoch 14, CIFAR-10 Batch 1:Loss:     0.0081 Validation Accuracy: 0.7337999939918518:.6f\n",
      "Epoch 14, CIFAR-10 Batch 2:Loss:     0.0035 Validation Accuracy: 0.7401999831199646:.6f\n",
      "Epoch 14, CIFAR-10 Batch 3:Loss:     0.0028 Validation Accuracy: 0.7275999784469604:.6f\n",
      "Epoch 14, CIFAR-10 Batch 4:Loss:     0.0021 Validation Accuracy: 0.7585999965667725:.6f\n",
      "Epoch 14, CIFAR-10 Batch 5:Loss:     0.0050 Validation Accuracy: 0.7350000143051147:.6f\n",
      "Epoch 15, CIFAR-10 Batch 1:Loss:     0.0135 Validation Accuracy: 0.7337999939918518:.6f\n",
      "Epoch 15, CIFAR-10 Batch 2:Loss:     0.0069 Validation Accuracy: 0.7342000007629395:.6f\n",
      "Epoch 15, CIFAR-10 Batch 3:Loss:     0.0071 Validation Accuracy: 0.7196000218391418:.6f\n",
      "Epoch 15, CIFAR-10 Batch 4:Loss:     0.0041 Validation Accuracy: 0.7462000250816345:.6f\n",
      "Epoch 15, CIFAR-10 Batch 5:Loss:     0.0054 Validation Accuracy: 0.7369999885559082:.6f\n",
      "Epoch 16, CIFAR-10 Batch 1:Loss:     0.0087 Validation Accuracy: 0.746399998664856:.6f\n",
      "Epoch 16, CIFAR-10 Batch 2:Loss:     0.0054 Validation Accuracy: 0.7329999804496765:.6f\n",
      "Epoch 16, CIFAR-10 Batch 3:Loss:     0.0040 Validation Accuracy: 0.7224000096321106:.6f\n",
      "Epoch 16, CIFAR-10 Batch 4:Loss:     0.0052 Validation Accuracy: 0.7429999709129333:.6f\n",
      "Epoch 16, CIFAR-10 Batch 5:Loss:     0.0052 Validation Accuracy: 0.7429999709129333:.6f\n",
      "Epoch 17, CIFAR-10 Batch 1:Loss:     0.0081 Validation Accuracy: 0.7351999878883362:.6f\n",
      "Epoch 17, CIFAR-10 Batch 2:Loss:     0.0051 Validation Accuracy: 0.7441999912261963:.6f\n",
      "Epoch 17, CIFAR-10 Batch 3:Loss:     0.0030 Validation Accuracy: 0.7422000169754028:.6f\n",
      "Epoch 17, CIFAR-10 Batch 4:Loss:     0.0043 Validation Accuracy: 0.7418000102043152:.6f\n",
      "Epoch 17, CIFAR-10 Batch 5:Loss:     0.0008 Validation Accuracy: 0.7409999966621399:.6f\n",
      "Epoch 18, CIFAR-10 Batch 1:Loss:     0.0206 Validation Accuracy: 0.7297999858856201:.6f\n",
      "Epoch 18, CIFAR-10 Batch 2:Loss:     0.0032 Validation Accuracy: 0.7360000014305115:.6f\n",
      "Epoch 18, CIFAR-10 Batch 3:Loss:     0.0147 Validation Accuracy: 0.7390000224113464:.6f\n",
      "Epoch 18, CIFAR-10 Batch 4:Loss:     0.0023 Validation Accuracy: 0.7541999816894531:.6f\n",
      "Epoch 18, CIFAR-10 Batch 5:Loss:     0.0106 Validation Accuracy: 0.7333999872207642:.6f\n",
      "Epoch 19, CIFAR-10 Batch 1:Loss:     0.0153 Validation Accuracy: 0.7350000143051147:.6f\n",
      "Epoch 19, CIFAR-10 Batch 2:Loss:     0.0150 Validation Accuracy: 0.7383999824523926:.6f\n",
      "Epoch 19, CIFAR-10 Batch 3:Loss:     0.0054 Validation Accuracy: 0.7422000169754028:.6f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, CIFAR-10 Batch 4:Loss:     0.0636 Validation Accuracy: 0.7354000210762024:.6f\n",
      "Epoch 19, CIFAR-10 Batch 5:Loss:     0.0005 Validation Accuracy: 0.7476000189781189:.6f\n",
      "Epoch 20, CIFAR-10 Batch 1:Loss:     0.0065 Validation Accuracy: 0.7350000143051147:.6f\n",
      "Epoch 20, CIFAR-10 Batch 2:Loss:     0.0046 Validation Accuracy: 0.7369999885559082:.6f\n",
      "Epoch 20, CIFAR-10 Batch 3:Loss:     0.0068 Validation Accuracy: 0.7423999905586243:.6f\n",
      "Epoch 20, CIFAR-10 Batch 4:Loss:     0.0087 Validation Accuracy: 0.7487999796867371:.6f\n",
      "Epoch 20, CIFAR-10 Batch 5:Loss:     0.0034 Validation Accuracy: 0.7445999979972839:.6f\n",
      "Epoch 21, CIFAR-10 Batch 1:Loss:     0.0235 Validation Accuracy: 0.732200026512146:.6f\n",
      "Epoch 21, CIFAR-10 Batch 2:Loss:     0.0037 Validation Accuracy: 0.7378000020980835:.6f\n",
      "Epoch 21, CIFAR-10 Batch 3:Loss:     0.0026 Validation Accuracy: 0.7379999756813049:.6f\n",
      "Epoch 21, CIFAR-10 Batch 4:Loss:     0.0020 Validation Accuracy: 0.7324000000953674:.6f\n",
      "Epoch 21, CIFAR-10 Batch 5:Loss:     0.0067 Validation Accuracy: 0.7296000123023987:.6f\n",
      "Epoch 22, CIFAR-10 Batch 1:Loss:     0.0040 Validation Accuracy: 0.734000027179718:.6f\n",
      "Epoch 22, CIFAR-10 Batch 2:Loss:     0.0013 Validation Accuracy: 0.7373999953269958:.6f\n",
      "Epoch 22, CIFAR-10 Batch 3:Loss:     0.0028 Validation Accuracy: 0.7315999865531921:.6f\n",
      "Epoch 22, CIFAR-10 Batch 4:Loss:     0.0076 Validation Accuracy: 0.7414000034332275:.6f\n",
      "Epoch 22, CIFAR-10 Batch 5:Loss:     0.0285 Validation Accuracy: 0.7328000068664551:.6f\n",
      "Epoch 23, CIFAR-10 Batch 1:Loss:     0.0070 Validation Accuracy: 0.7346000075340271:.6f\n",
      "Epoch 23, CIFAR-10 Batch 2:Loss:     0.0004 Validation Accuracy: 0.729200005531311:.6f\n",
      "Epoch 23, CIFAR-10 Batch 3:Loss:     0.0038 Validation Accuracy: 0.7261999845504761:.6f\n",
      "Epoch 23, CIFAR-10 Batch 4:Loss:     0.0024 Validation Accuracy: 0.7346000075340271:.6f\n",
      "Epoch 23, CIFAR-10 Batch 5:Loss:     0.0086 Validation Accuracy: 0.7125999927520752:.6f\n",
      "Epoch 24, CIFAR-10 Batch 1:Loss:     0.0264 Validation Accuracy: 0.7432000041007996:.6f\n",
      "Epoch 24, CIFAR-10 Batch 2:Loss:     0.0108 Validation Accuracy: 0.7473999857902527:.6f\n",
      "Epoch 24, CIFAR-10 Batch 3:Loss:     0.0025 Validation Accuracy: 0.7490000128746033:.6f\n",
      "Epoch 24, CIFAR-10 Batch 4:Loss:     0.0110 Validation Accuracy: 0.7297999858856201:.6f\n",
      "Epoch 24, CIFAR-10 Batch 5:Loss:     0.0018 Validation Accuracy: 0.7305999994277954:.6f\n",
      "Epoch 25, CIFAR-10 Batch 1:Loss:     0.0026 Validation Accuracy: 0.7382000088691711:.6f\n",
      "Epoch 25, CIFAR-10 Batch 2:Loss:     0.0048 Validation Accuracy: 0.7504000067710876:.6f\n",
      "Epoch 25, CIFAR-10 Batch 3:Loss:     0.0535 Validation Accuracy: 0.7297999858856201:.6f\n",
      "Epoch 25, CIFAR-10 Batch 4:Loss:     0.0031 Validation Accuracy: 0.7364000082015991:.6f\n",
      "Epoch 25, CIFAR-10 Batch 5:Loss:     0.0500 Validation Accuracy: 0.7454000115394592:.6f\n",
      "Epoch 26, CIFAR-10 Batch 1:Loss:     0.0008 Validation Accuracy: 0.746999979019165:.6f\n",
      "Epoch 26, CIFAR-10 Batch 2:Loss:     0.0068 Validation Accuracy: 0.7342000007629395:.6f\n",
      "Epoch 26, CIFAR-10 Batch 3:Loss:     0.0015 Validation Accuracy: 0.7315999865531921:.6f\n",
      "Epoch 26, CIFAR-10 Batch 4:Loss:     0.0007 Validation Accuracy: 0.7513999938964844:.6f\n",
      "Epoch 26, CIFAR-10 Batch 5:Loss:     0.0018 Validation Accuracy: 0.7429999709129333:.6f\n",
      "Epoch 27, CIFAR-10 Batch 1:Loss:     0.0140 Validation Accuracy: 0.7418000102043152:.6f\n",
      "Epoch 27, CIFAR-10 Batch 2:Loss:     0.0009 Validation Accuracy: 0.7549999952316284:.6f\n",
      "Epoch 27, CIFAR-10 Batch 3:Loss:     0.0080 Validation Accuracy: 0.7365999817848206:.6f\n",
      "Epoch 27, CIFAR-10 Batch 4:Loss:     0.0037 Validation Accuracy: 0.7310000061988831:.6f\n",
      "Epoch 27, CIFAR-10 Batch 5:Loss:     0.0040 Validation Accuracy: 0.7555999755859375:.6f\n",
      "Epoch 28, CIFAR-10 Batch 1:Loss:     0.0025 Validation Accuracy: 0.7400000095367432:.6f\n",
      "Epoch 28, CIFAR-10 Batch 2:Loss:     0.0023 Validation Accuracy: 0.7368000149726868:.6f\n",
      "Epoch 28, CIFAR-10 Batch 3:Loss:     0.0002 Validation Accuracy: 0.746399998664856:.6f\n",
      "Epoch 28, CIFAR-10 Batch 4:Loss:     0.0062 Validation Accuracy: 0.7319999933242798:.6f\n",
      "Epoch 28, CIFAR-10 Batch 5:Loss:     0.0016 Validation Accuracy: 0.7501999735832214:.6f\n",
      "Epoch 29, CIFAR-10 Batch 1:Loss:     0.0065 Validation Accuracy: 0.7200000286102295:.6f\n",
      "Epoch 29, CIFAR-10 Batch 2:Loss:     0.0093 Validation Accuracy: 0.7454000115394592:.6f\n",
      "Epoch 29, CIFAR-10 Batch 3:Loss:     0.0012 Validation Accuracy: 0.7400000095367432:.6f\n",
      "Epoch 29, CIFAR-10 Batch 4:Loss:     0.0119 Validation Accuracy: 0.7445999979972839:.6f\n",
      "Epoch 29, CIFAR-10 Batch 5:Loss:     0.0045 Validation Accuracy: 0.7441999912261963:.6f\n",
      "Epoch 30, CIFAR-10 Batch 1:Loss:     0.0020 Validation Accuracy: 0.7361999750137329:.6f\n",
      "Epoch 30, CIFAR-10 Batch 2:Loss:     0.0005 Validation Accuracy: 0.7487999796867371:.6f\n",
      "Epoch 30, CIFAR-10 Batch 3:Loss:     0.0005 Validation Accuracy: 0.7376000285148621:.6f\n",
      "Epoch 30, CIFAR-10 Batch 4:Loss:     0.0036 Validation Accuracy: 0.7365999817848206:.6f\n",
      "Epoch 30, CIFAR-10 Batch 5:Loss:     0.0029 Validation Accuracy: 0.7329999804496765:.6f\n",
      "Epoch 31, CIFAR-10 Batch 1:Loss:     0.0008 Validation Accuracy: 0.7414000034332275:.6f\n",
      "Epoch 31, CIFAR-10 Batch 2:Loss:     0.0065 Validation Accuracy: 0.7408000230789185:.6f\n",
      "Epoch 31, CIFAR-10 Batch 3:Loss:     0.0008 Validation Accuracy: 0.7501999735832214:.6f\n",
      "Epoch 31, CIFAR-10 Batch 4:Loss:     0.0044 Validation Accuracy: 0.7328000068664551:.6f\n",
      "Epoch 31, CIFAR-10 Batch 5:Loss:     0.0004 Validation Accuracy: 0.7480000257492065:.6f\n",
      "Epoch 32, CIFAR-10 Batch 1:Loss:     0.0008 Validation Accuracy: 0.7440000176429749:.6f\n",
      "Epoch 32, CIFAR-10 Batch 2:Loss:     0.0088 Validation Accuracy: 0.7504000067710876:.6f\n",
      "Epoch 32, CIFAR-10 Batch 3:Loss:     0.0113 Validation Accuracy: 0.7409999966621399:.6f\n",
      "Epoch 32, CIFAR-10 Batch 4:Loss:     0.0008 Validation Accuracy: 0.7394000291824341:.6f\n",
      "Epoch 32, CIFAR-10 Batch 5:Loss:     0.0006 Validation Accuracy: 0.7458000183105469:.6f\n",
      "Epoch 33, CIFAR-10 Batch 1:Loss:     0.0029 Validation Accuracy: 0.7462000250816345:.6f\n",
      "Epoch 33, CIFAR-10 Batch 2:Loss:     0.0019 Validation Accuracy: 0.7444000244140625:.6f\n",
      "Epoch 33, CIFAR-10 Batch 3:Loss:     0.0002 Validation Accuracy: 0.7476000189781189:.6f\n",
      "Epoch 33, CIFAR-10 Batch 4:Loss:     0.0007 Validation Accuracy: 0.7423999905586243:.6f\n",
      "Epoch 33, CIFAR-10 Batch 5:Loss:     0.0004 Validation Accuracy: 0.7429999709129333:.6f\n",
      "Epoch 34, CIFAR-10 Batch 1:Loss:     0.0029 Validation Accuracy: 0.7534000277519226:.6f\n",
      "Epoch 34, CIFAR-10 Batch 2:Loss:     0.0015 Validation Accuracy: 0.7544000148773193:.6f\n",
      "Epoch 34, CIFAR-10 Batch 3:Loss:     0.0035 Validation Accuracy: 0.7573999762535095:.6f\n",
      "Epoch 34, CIFAR-10 Batch 4:Loss:     0.0019 Validation Accuracy: 0.7365999817848206:.6f\n",
      "Epoch 34, CIFAR-10 Batch 5:Loss:     0.0063 Validation Accuracy: 0.7501999735832214:.6f\n",
      "Epoch 35, CIFAR-10 Batch 1:Loss:     0.0105 Validation Accuracy: 0.7328000068664551:.6f\n",
      "Epoch 35, CIFAR-10 Batch 2:Loss:     0.0016 Validation Accuracy: 0.7459999918937683:.6f\n",
      "Epoch 35, CIFAR-10 Batch 3:Loss:     0.0004 Validation Accuracy: 0.7458000183105469:.6f\n",
      "Epoch 35, CIFAR-10 Batch 4:Loss:     0.0008 Validation Accuracy: 0.7404000163078308:.6f\n",
      "Epoch 35, CIFAR-10 Batch 5:Loss:     0.0004 Validation Accuracy: 0.7512000203132629:.6f\n",
      "Epoch 36, CIFAR-10 Batch 1:Loss:     0.0074 Validation Accuracy: 0.7301999926567078:.6f\n",
      "Epoch 36, CIFAR-10 Batch 2:Loss:     0.0112 Validation Accuracy: 0.7418000102043152:.6f\n",
      "Epoch 36, CIFAR-10 Batch 3:Loss:     0.0135 Validation Accuracy: 0.7554000020027161:.6f\n",
      "Epoch 36, CIFAR-10 Batch 4:Loss:     0.0012 Validation Accuracy: 0.751800000667572:.6f\n",
      "Epoch 36, CIFAR-10 Batch 5:Loss:     0.0009 Validation Accuracy: 0.739799976348877:.6f\n",
      "Epoch 37, CIFAR-10 Batch 1:Loss:     0.0017 Validation Accuracy: 0.7544000148773193:.6f\n",
      "Epoch 37, CIFAR-10 Batch 2:Loss:     0.0043 Validation Accuracy: 0.7526000142097473:.6f\n",
      "Epoch 37, CIFAR-10 Batch 3:Loss:     0.0007 Validation Accuracy: 0.7310000061988831:.6f\n",
      "Epoch 37, CIFAR-10 Batch 4:Loss:     0.0009 Validation Accuracy: 0.7545999884605408:.6f\n",
      "Epoch 37, CIFAR-10 Batch 5:Loss:     0.0016 Validation Accuracy: 0.7325999736785889:.6f\n",
      "Epoch 38, CIFAR-10 Batch 1:Loss:     0.0015 Validation Accuracy: 0.7354000210762024:.6f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, CIFAR-10 Batch 2:Loss:     0.0014 Validation Accuracy: 0.7411999702453613:.6f\n",
      "Epoch 38, CIFAR-10 Batch 3:Loss:     0.0061 Validation Accuracy: 0.741599977016449:.6f\n",
      "Epoch 38, CIFAR-10 Batch 4:Loss:     0.0021 Validation Accuracy: 0.7491999864578247:.6f\n",
      "Epoch 38, CIFAR-10 Batch 5:Loss:     0.0010 Validation Accuracy: 0.7480000257492065:.6f\n",
      "Epoch 39, CIFAR-10 Batch 1:Loss:     0.0022 Validation Accuracy: 0.7540000081062317:.6f\n",
      "Epoch 39, CIFAR-10 Batch 2:Loss:     0.0001 Validation Accuracy: 0.7486000061035156:.6f\n",
      "Epoch 39, CIFAR-10 Batch 3:Loss:     0.0011 Validation Accuracy: 0.7509999871253967:.6f\n",
      "Epoch 39, CIFAR-10 Batch 4:Loss:     0.0068 Validation Accuracy: 0.7404000163078308:.6f\n",
      "Epoch 39, CIFAR-10 Batch 5:Loss:     0.0005 Validation Accuracy: 0.748199999332428:.6f\n",
      "Epoch 40, CIFAR-10 Batch 1:Loss:     0.0008 Validation Accuracy: 0.7516000270843506:.6f\n",
      "Epoch 40, CIFAR-10 Batch 2:Loss:     0.0004 Validation Accuracy: 0.7476000189781189:.6f\n",
      "Epoch 40, CIFAR-10 Batch 3:Loss:     0.0018 Validation Accuracy: 0.7390000224113464:.6f\n",
      "Epoch 40, CIFAR-10 Batch 4:Loss:     0.0004 Validation Accuracy: 0.7432000041007996:.6f\n",
      "Epoch 40, CIFAR-10 Batch 5:Loss:     0.0009 Validation Accuracy: 0.7404000163078308:.6f\n",
      "Epoch 41, CIFAR-10 Batch 1:Loss:     0.0043 Validation Accuracy: 0.7329999804496765:.6f\n",
      "Epoch 41, CIFAR-10 Batch 2:Loss:     0.0028 Validation Accuracy: 0.7418000102043152:.6f\n",
      "Epoch 41, CIFAR-10 Batch 3:Loss:     0.0009 Validation Accuracy: 0.7508000135421753:.6f\n",
      "Epoch 41, CIFAR-10 Batch 4:Loss:     0.0244 Validation Accuracy: 0.7572000026702881:.6f\n",
      "Epoch 41, CIFAR-10 Batch 5:Loss:     0.0004 Validation Accuracy: 0.751800000667572:.6f\n",
      "Epoch 42, CIFAR-10 Batch 1:Loss:     0.0090 Validation Accuracy: 0.7373999953269958:.6f\n",
      "Epoch 42, CIFAR-10 Batch 2:Loss:     0.0001 Validation Accuracy: 0.7454000115394592:.6f\n",
      "Epoch 42, CIFAR-10 Batch 3:Loss:     0.0096 Validation Accuracy: 0.7369999885559082:.6f\n",
      "Epoch 42, CIFAR-10 Batch 4:Loss:     0.0024 Validation Accuracy: 0.7580000162124634:.6f\n",
      "Epoch 42, CIFAR-10 Batch 5:Loss:     0.0036 Validation Accuracy: 0.7523999810218811:.6f\n",
      "Epoch 43, CIFAR-10 Batch 1:Loss:     0.0007 Validation Accuracy: 0.7505999803543091:.6f\n",
      "Epoch 43, CIFAR-10 Batch 2:Loss:     0.0012 Validation Accuracy: 0.7364000082015991:.6f\n",
      "Epoch 43, CIFAR-10 Batch 3:Loss:     0.0008 Validation Accuracy: 0.7594000101089478:.6f\n",
      "Epoch 43, CIFAR-10 Batch 4:Loss:     0.0004 Validation Accuracy: 0.7429999709129333:.6f\n",
      "Epoch 43, CIFAR-10 Batch 5:Loss:     0.0022 Validation Accuracy: 0.7504000067710876:.6f\n",
      "Epoch 44, CIFAR-10 Batch 1:Loss:     0.0038 Validation Accuracy: 0.7544000148773193:.6f\n",
      "Epoch 44, CIFAR-10 Batch 2:Loss:     0.0001 Validation Accuracy: 0.7487999796867371:.6f\n",
      "Epoch 44, CIFAR-10 Batch 3:Loss:     0.0012 Validation Accuracy: 0.7531999945640564:.6f\n",
      "Epoch 44, CIFAR-10 Batch 4:Loss:     0.0012 Validation Accuracy: 0.7585999965667725:.6f\n",
      "Epoch 44, CIFAR-10 Batch 5:Loss:     0.0014 Validation Accuracy: 0.7473999857902527:.6f\n",
      "Epoch 45, CIFAR-10 Batch 1:Loss:     0.0003 Validation Accuracy: 0.7559999823570251:.6f\n",
      "Epoch 45, CIFAR-10 Batch 2:Loss:     0.0021 Validation Accuracy: 0.7351999878883362:.6f\n",
      "Epoch 45, CIFAR-10 Batch 3:Loss:     0.0004 Validation Accuracy: 0.7422000169754028:.6f\n",
      "Epoch 45, CIFAR-10 Batch 4:Loss:     0.0019 Validation Accuracy: 0.7562000155448914:.6f\n",
      "Epoch 45, CIFAR-10 Batch 5:Loss:     0.0054 Validation Accuracy: 0.75:.6f\n",
      "Epoch 46, CIFAR-10 Batch 1:Loss:     0.0049 Validation Accuracy: 0.7436000108718872:.6f\n",
      "Epoch 46, CIFAR-10 Batch 2:Loss:     0.0008 Validation Accuracy: 0.734000027179718:.6f\n",
      "Epoch 46, CIFAR-10 Batch 3:Loss:     0.0038 Validation Accuracy: 0.7365999817848206:.6f\n",
      "Epoch 46, CIFAR-10 Batch 4:Loss:     0.0006 Validation Accuracy: 0.7444000244140625:.6f\n",
      "Epoch 46, CIFAR-10 Batch 5:Loss:     0.0009 Validation Accuracy: 0.7531999945640564:.6f\n",
      "Epoch 47, CIFAR-10 Batch 1:Loss:     0.0046 Validation Accuracy: 0.727400004863739:.6f\n",
      "Epoch 47, CIFAR-10 Batch 2:Loss:     0.0091 Validation Accuracy: 0.7422000169754028:.6f\n",
      "Epoch 47, CIFAR-10 Batch 3:Loss:     0.0004 Validation Accuracy: 0.7562000155448914:.6f\n",
      "Epoch 47, CIFAR-10 Batch 4:Loss:     0.0059 Validation Accuracy: 0.7509999871253967:.6f\n",
      "Epoch 47, CIFAR-10 Batch 5:Loss:     0.0001 Validation Accuracy: 0.7591999769210815:.6f\n",
      "Epoch 48, CIFAR-10 Batch 1:Loss:     0.0038 Validation Accuracy: 0.7387999892234802:.6f\n",
      "Epoch 48, CIFAR-10 Batch 2:Loss:     0.0003 Validation Accuracy: 0.7465999722480774:.6f\n",
      "Epoch 48, CIFAR-10 Batch 3:Loss:     0.0004 Validation Accuracy: 0.7465999722480774:.6f\n",
      "Epoch 48, CIFAR-10 Batch 4:Loss:     0.0020 Validation Accuracy: 0.7400000095367432:.6f\n",
      "Epoch 48, CIFAR-10 Batch 5:Loss:     0.0018 Validation Accuracy: 0.7455999851226807:.6f\n",
      "Epoch 49, CIFAR-10 Batch 1:Loss:     0.0002 Validation Accuracy: 0.7513999938964844:.6f\n",
      "Epoch 49, CIFAR-10 Batch 2:Loss:     0.0004 Validation Accuracy: 0.7567999958992004:.6f\n",
      "Epoch 49, CIFAR-10 Batch 3:Loss:     0.0003 Validation Accuracy: 0.7534000277519226:.6f\n",
      "Epoch 49, CIFAR-10 Batch 4:Loss:     0.0010 Validation Accuracy: 0.7490000128746033:.6f\n",
      "Epoch 49, CIFAR-10 Batch 5:Loss:     0.0097 Validation Accuracy: 0.7365999817848206:.6f\n",
      "Epoch 50, CIFAR-10 Batch 1:Loss:     0.0011 Validation Accuracy: 0.7445999979972839:.6f\n",
      "Epoch 50, CIFAR-10 Batch 2:Loss:     0.0047 Validation Accuracy: 0.7408000230789185:.6f\n",
      "Epoch 50, CIFAR-10 Batch 3:Loss:     0.0011 Validation Accuracy: 0.7432000041007996:.6f\n",
      "Epoch 50, CIFAR-10 Batch 4:Loss:     0.0021 Validation Accuracy: 0.7459999918937683:.6f\n",
      "Epoch 50, CIFAR-10 Batch 5:Loss:     0.0002 Validation Accuracy: 0.7437999844551086:.6f\n"
     ]
    }
   ],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training!...')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        nbatch = 5\n",
    "        for batchindex in range(1, nbatch + 1):\n",
    "            for batchfeatures, batchlbls in load_preproc_train_batch(batchindex, batch_size):\n",
    "                train_nn(sess, optimizer, keep_probability, batchfeatures, batchlbls)\n",
    "                \n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:'.format(epoch + 1, batchindex), end='')\n",
    "            print_stats(sess, batchfeatures, batchlbls, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint\n",
    "\n",
    "The model has been saved to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features_lbl(features, lbls, batch_size):\n",
    "    '''\n",
    "    Split features and labels into batches\n",
    "    '''\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], lbls[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img_predict(features, lbls, predictions, top_n_predictions):\n",
    "    nclasses = 10\n",
    "    lblbinarizer = LabelBinarizer()\n",
    "    lblbinarizer.fit(range(nclasses))\n",
    "    lblids = lblbinarizer.inverse_transform(np.array(lbls))\n",
    "    \n",
    "    fig, axies = plt.subplots(nrows=top_n_predictions, ncols=2, figsize=(20, 10))\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "    \n",
    "    n_predictions = 3\n",
    "    margin = .05\n",
    "    ind = np.arange(n_predictions)\n",
    "    width = (1. - 2. * margin) / n_predictions\n",
    "    \n",
    "    for image_i, (feature, lblid, pred_indices, pred_values) in enumerate(zip(features, lblids, predictions.indices, predictions.values)):\n",
    "        if (image_i < top_n_predictions):\n",
    "            pred_names = [lblnames[pred_i] for pred_i in pred_indices]\n",
    "            correct_name = lblnames[lblid]\n",
    "            \n",
    "            axies[image_i][0].imshow((feature * 255).astype(np.int32, copy=False))\n",
    "            axies[image_i][0].set_title(correct_name)\n",
    "            axies[image_i][0].set_axis_off()\n",
    "            \n",
    "            axies[image_i][1].barh(ind + margin, pred_values[:3], width)\n",
    "            axies[image_i][1].set_yticks(ind + margin)\n",
    "            axies[image_i][1].set_yticklabels(pred_names[::1])\n",
    "            axies[image_i][1].set_xticks([0, .5, 1.])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = './image_classification'\n",
    "batch_size = 64\n",
    "nsamples =10\n",
    "top_n_predictions = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testmodel():\n",
    "    testfeatures, testlbls = pickle.load(open('preprocess.training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "    \n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        \n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "        \n",
    "        # Get Tensors from Loaded model\n",
    "        loadedx = loaded_graph.get_tensor_by_name('output_x:0')\n",
    "        loadedy = loaded_graph.get_tensor_by_name('output_y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in batch_features_lbl(testfeatures, testlbls, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loadedx: train_feature_batch,\n",
    "                          loadedy: train_label_batch,\n",
    "                           loaded_keep_prob: 1.\n",
    "                          })\n",
    "            test_batch_count += 1\n",
    "            \n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total / test_batch_count))\n",
    "        \n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(testfeatures, testlbls)), nsamples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict = {loadedx: random_test_features,\n",
    "                        loadedy: random_test_labels,\n",
    "                        loaded_keep_prob: 1.})\n",
    "        display_img_predict(random_test_features, random_test_labels, random_test_predictions, top_n_predictions)\n",
    "        \n",
    "testmodel()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
